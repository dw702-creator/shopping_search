import streamlit as st
import requests
from bs4 import BeautifulSoup
import urllib.parse
import time

st.set_page_config(page_title="Clothing Search Online", layout="wide")
st.title("ì˜¨ë¼ì¸ ì˜ë¥˜ ê²€ìƒ‰ê¸°")

type_ = st.text_input("ì¢…ë¥˜ (ì˜ˆ: hoodie, sweatshirt, jacket, í‹°ì…”ì¸  ë“±)", "")
color = st.text_input("ìƒ‰ê¹” (ì˜ˆ: grey, black, white, blue ë“±)", "")
design = st.text_input("ë””ìì¸ í‚¤ì›Œë“œ (ì˜ˆ: black text, graphic, ë¡œê³  ë“±)", "")

SEARCH_COUNT = st.sidebar.number_input("ìµœëŒ€ ê²€ìƒ‰ ê²°ê³¼ ìˆ˜ (per ì‚¬ì´íŠ¸)", min_value=5, max_value=50, value=10)

def build_query(type_, color, design):
    pieces = []
    if type_:
        pieces.append(type_)
    if color:
        pieces.append(color)
    if design:
        pieces += design.split()
    return " ".join(pieces)

def search_naver_shopping(query, max_results=10):
    url = "https://search.shopping.naver.com/search/all"
    params = {"query": query}
    headers = {"User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64)"}
    resp = requests.get(url, params=params, headers=headers, timeout=10)
    resp.raise_for_status()
    soup = BeautifulSoup(resp.text, "html.parser")
    items = []
    for item in soup.select("a.basicList_link__JLQJf")[:max_results]:
        title = item.get_text().strip()
        link = item.get("href")
        items.append({"title": title, "link": link, "source": "Naver Shopping"})
    return items

def search_google(query, max_results=10):
    # Note: êµ¬ê¸€ì€ í¬ë¡¤ë§ ë°©ì§€ ì •ì±…ì´ ìˆìŒ â€” ì˜ ë™ì‘í•˜ì§€ ì•Šì„ ìˆ˜ ìˆìŒ
    url = "https://www.google.com/search"
    params = {"q": query + " ì˜ë¥˜", "num": max_results}
    headers = {"User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64)"}
    resp = requests.get(url, params=params, headers=headers, timeout=10)
    resp.raise_for_status()
    soup = BeautifulSoup(resp.text, "html.parser")
    results = []
    for g in soup.select("div.g")[:max_results]:
        a = g.select_one("a")
        if not a:
            continue
        title = a.get_text().strip()
        link = a.get("href")
        # ê°„ë‹¨ í•„í„°: title ë˜ëŠ” snippet ì•ˆì— ìƒ‰ê¹”/ë””ìì¸ í‚¤ì›Œë“œ í¬í•¨ ì—¬ë¶€ í™•ì¸
        results.append({"title": title, "link": link, "source": "Google"})
    return results

if st.button("ê²€ìƒ‰"):
    query = build_query(type_.lower(), color.lower(), design.lower())
    st.write("ğŸ” ê²€ìƒ‰ì–´:", query)
    results = []
    try:
        results += search_naver_shopping(query, SEARCH_COUNT)
    except Exception as e:
        st.write("ë„¤ì´ë²„ ì‡¼í•‘ ê²€ìƒ‰ ì‹¤íŒ¨:", e)
    try:
        results += search_google(query, SEARCH_COUNT)
    except Exception as e:
        st.write("êµ¬ê¸€ ê²€ìƒ‰ ì‹¤íŒ¨:", e)

    if results:
        st.write(f"{len(results)}ê°œ ê²°ê³¼ (ìµœëŒ€ {SEARCH_COUNT} per ì‚¬ì´íŠ¸).")
        for r in results:
            st.write(f"- **{r['title']}** â€” {r['source']} â€” [ë§í¬ ì—´ê¸°]({r['link']})")
    else:
        st.write("ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. ê²€ìƒ‰ì–´ë¥¼ ë°”ê¿” ë³´ì„¸ìš”.")
